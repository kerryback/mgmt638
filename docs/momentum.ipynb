{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Momentum Calculation\n",
    "\n",
    "This notebook calculates momentum for all stocks in the Rice Business Stock Market Data Portal.\n",
    "\n",
    "Momentum is defined as:\n",
    "- (Price 1 month ago / Price 12 months ago) - 1\n",
    "\n",
    "This captures the return from 12 months ago to 1 month ago, which is a common momentum measure that skips the most recent month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Connect to Rice Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rice_data_client import RiceDataClient\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get configuration from environment\n",
    "ACCESS_TOKEN = os.getenv('USER_ACCESS_TOKEN')\n",
    "BASE_URL = os.getenv('RICE_DATA_URL', 'https://portal.rice-business.org')\n",
    "\n",
    "# Connect to Rice Data Portal\n",
    "client = RiceDataClient(\n",
    "    access_token=ACCESS_TOKEN,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "print(\"Connected to Rice Data Portal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Query Daily Prices Year by Year\n\nThe SEP table contains daily prices. We'll download data one year at a time to avoid timeouts, then filter in Python to get only the last trading day of each month."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set the start year for data download\nstart_year = 2023\n\n# Get current year\nimport datetime\ncurrent_year = datetime.datetime.now().year\n\n# Initialize empty list to collect end-of-month data only\nall_data = []\n\n# Loop through years from start_year to current year\nfor year in range(start_year, current_year + 1):\n    print(f\"Downloading data for {year}...\")\n    \n    # SQL query to get daily adjusted closing prices for one year\n    sql = f\"\"\"\n    SELECT \n        ticker,\n        date,\n        closeadj\n    FROM sep\n    WHERE date::DATE >= '{year}-01-01' \n      AND date::DATE < '{year + 1}-01-01'\n    ORDER BY ticker, date\n    \"\"\"\n    \n    # Execute query\n    df_year = client.query(sql)\n    print(f\"  Downloaded {len(df_year):,} daily observations\")\n    \n    # Convert date to datetime\n    df_year['date'] = pd.to_datetime(df_year['date'])\n    \n    # Filter to end-of-month dates for this year\n    # This reduces memory usage by filtering before accumulating\n    df_year['year_month'] = df_year['date'].dt.to_period('M')\n    df_month_end = df_year.groupby(['ticker', 'year_month']).apply(\n        lambda x: x.loc[x['date'].idxmax()]\n    ).reset_index(drop=True)\n    df_month_end = df_month_end.drop(columns=['year_month'])\n    \n    print(f\"  Filtered to {len(df_month_end):,} end-of-month observations\")\n    \n    # Keep only the end-of-month data\n    all_data.append(df_month_end)\n    # df_year is no longer referenced and will be garbage collected\n\n# Combine all years into one dataframe\nprint(\"\\nCombining all years...\")\ndf = pd.concat(all_data, ignore_index=True)\nprint(f\"Total: {len(df):,} end-of-month observations for {df['ticker'].nunique():,} tickers\")\n\n# Display first few rows\ndf.head(10)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sort by ticker and date\n",
    "df = df.sort_values(['ticker', 'date'])\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"  Start: {df['date'].min()}\")\n",
    "print(f\"  End: {df['date'].max()}\")\n",
    "print(f\"\\nNumber of tickers: {df['ticker'].nunique():,}\")\n",
    "print(f\"Total observations: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Momentum\n",
    "\n",
    "Momentum = (Price 1 month ago / Price 12 months ago) - 1\n",
    "\n",
    "We use `.shift(1)` to get the price 1 month ago and `.shift(12)` to get the price 12 months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lagged prices by ticker\n",
    "df['price_lag1'] = df.groupby('ticker')['closeadj'].shift(1)\n",
    "df['price_lag12'] = df.groupby('ticker')['closeadj'].shift(12)\n",
    "\n",
    "# Calculate momentum\n",
    "df['momentum'] = (df['price_lag1'] / df['price_lag12']) - 1\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nMomentum calculated for {df['momentum'].notna().sum():,} observations\")\n",
    "print(f\"Missing momentum values: {df['momentum'].isna().sum():,}\")\n",
    "\n",
    "# Show first few rows with momentum\n",
    "df[['ticker', 'date', 'closeadj', 'price_lag1', 'price_lag12', 'momentum']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing momentum values for statistics\n",
    "df_clean = df.dropna(subset=['momentum'])\n",
    "\n",
    "print(\"Momentum Summary Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(df_clean['momentum'].describe())\n",
    "\n",
    "# Additional statistics\n",
    "print(f\"\\nPercentiles:\")\n",
    "print(f\"  10th: {df_clean['momentum'].quantile(0.10):.4f}\")\n",
    "print(f\"  25th: {df_clean['momentum'].quantile(0.25):.4f}\")\n",
    "print(f\"  50th: {df_clean['momentum'].quantile(0.50):.4f}\")\n",
    "print(f\"  75th: {df_clean['momentum'].quantile(0.75):.4f}\")\n",
    "print(f\"  90th: {df_clean['momentum'].quantile(0.90):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Momentum Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histogram of momentum values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Full distribution\n",
    "axes[0].hist(df_clean['momentum'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Momentum')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Momentum Distribution (All Values)')\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zoomed in distribution (between -1 and 2)\n",
    "df_zoom = df_clean[(df_clean['momentum'] >= -1) & (df_clean['momentum'] <= 2)]\n",
    "axes[1].hist(df_zoom['momentum'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Momentum')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Momentum Distribution (Zoomed: -100% to +200%)')\n",
    "axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPercentage of stocks with positive momentum: {(df_clean['momentum'] > 0).mean() * 100:.1f}%\")\n",
    "print(f\"Percentage of stocks with negative momentum: {(df_clean['momentum'] < 0).mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: View Recent Momentum for Specific Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example tickers to examine\n",
    "example_tickers = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'JPM']\n",
    "\n",
    "# Get most recent 12 months of data for these tickers\n",
    "recent_data = df[df['ticker'].isin(example_tickers)].groupby('ticker').tail(12)\n",
    "\n",
    "# Display\n",
    "for ticker in example_tickers:\n",
    "    ticker_data = recent_data[recent_data['ticker'] == ticker][['date', 'closeadj', 'momentum']].tail(12)\n",
    "    if not ticker_data.empty:\n",
    "        print(f\"\\n{ticker}:\")\n",
    "        print(ticker_data.to_string(index=False))\n",
    "        latest_momentum = ticker_data['momentum'].iloc[-1]\n",
    "        if pd.notna(latest_momentum):\n",
    "            print(f\"Latest momentum: {latest_momentum:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Save Momentum Data to Disk\n\nWe'll save the momentum data in Parquet format, which offers several advantages:\n- **Smaller file size**: Compressed format, typically 5-10x smaller than CSV\n- **Preserves data types**: Dates and numbers are stored natively, no parsing needed when reading\n- **Faster I/O**: Quicker to read and write than CSV\n- **Industry standard**: Widely used in data science and finance\n\nTo read the data back later, use: `df = pd.read_parquet('momentum.parquet')`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Select relevant columns\noutput_df = df[['ticker', 'date', 'closeadj', 'momentum']].copy()\n\n# Save to Parquet format\noutput_filename = 'momentum.parquet'\noutput_df.to_parquet(output_filename, index=False)\n\nprint(f\"Momentum data saved to {output_filename}\")\nprint(f\"Total rows: {len(output_df):,}\")\nprint(f\"Rows with momentum: {output_df['momentum'].notna().sum():,}\")\n\n# Display file size\nimport os\nfile_size_mb = os.path.getsize(output_filename) / (1024 * 1024)\nprint(f\"File size: {file_size_mb:.2f} MB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook:\n1. Connected to Rice Data Portal using rice_data_client\n2. Downloaded daily adjusted closing prices from the SEP table year by year (to avoid timeouts)\n   - Start year is configurable (currently set to 2023)\n   - Filtered to end-of-month inside the loop to minimize memory usage\n3. Combined end-of-month prices from all years\n4. Calculated momentum for each stock as (Price_t-1 / Price_t-12) - 1\n5. Analyzed the distribution of momentum values\n6. Saved the results to a Parquet file for efficient storage and future use\n\n**Note**: The SEP table contains daily prices, not monthly prices. We filter for end-of-month dates after downloading.\n\nThe momentum measure skips the most recent month and looks at returns from 12 months ago to 1 month ago, which is a standard approach in momentum investing to avoid short-term reversals.\n\n**To use the saved data later:**\n```python\nimport pandas as pd\ndf_momentum = pd.read_parquet('momentum.parquet')\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}