{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM PE Prediction Analysis - November 2025\n",
    "\n",
    "This notebook trains a LightGBM model to predict PE ratios using October 2025 data to predict November 2025 PE ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_parquet('data3.parquet')\n",
    "df['month'] = pd.to_datetime(df['month'])\n",
    "\n",
    "print(f\"Total data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['month'].min()} to {df['month'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "categorical_features = ['sector', 'industry', 'size']\n",
    "numeric_features = [\n",
    "    'roe', 'roa', 'grossmargin', 'netmargin', 'assetturnover',\n",
    "    'equity_multiplier', 'payoutratio', 'gp_to_assets',\n",
    "    'revenue_5y_growth', 'netinc_5y_growth', 'eps_5y_growth',\n",
    "    'ebitda_5y_growth', 'assets_5y_growth', 'equity_5y_growth',\n",
    "    'debt_5y_growth', 'cashneq_5y_growth', 'ncfo_5y_growth',\n",
    "    'fcf_5y_growth', 'dps_5y_growth', 'payoutratio_5y_growth',\n",
    "    'assetturnover_5y_growth', 'equity_multiplier_5y_growth',\n",
    "    'gp_to_assets_5y_growth'\n",
    "]\n",
    "all_features = categorical_features + numeric_features\n",
    "\n",
    "print(f\"Total features: {len(all_features)}\")\n",
    "print(f\"Categorical: {len(categorical_features)}, Numeric: {len(numeric_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing PE or features\n",
    "df = df[df['pe'].notna() & (df['pe'] > 0)].copy()\n",
    "df = df.dropna(subset=all_features)\n",
    "\n",
    "print(f\"Data shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on October 2025, Predict November 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_month = pd.Timestamp('2025-10-01')\n",
    "test_month = pd.Timestamp('2025-11-01')\n",
    "\n",
    "train_data = df[df['month'] == train_month].copy()\n",
    "test_data = df[df['month'] == test_month].copy()\n",
    "\n",
    "print(f\"Training data: {len(train_data)} observations\")\n",
    "print(f\"Test data: {len(test_data)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_train = train_data[all_features].copy()\n",
    "y_train = train_data['pe']\n",
    "\n",
    "X_test = test_data[all_features].copy()\n",
    "y_test = test_data['pe']\n",
    "\n",
    "# Convert categorical features\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mape',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train model\n",
    "print(\"Training LightGBM model...\")\n",
    "model = lgb.LGBMRegressor(n_estimators=500, **params)\n",
    "model.fit(X_train, y_train, categorical_feature=categorical_features)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions and Calculate Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate percentage errors\n",
    "pct_error = ((y_pred - y_test) / y_test) * 100\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nPrediction Error Statistics:\")\n",
    "print(f\"Mean Absolute Percentage Error: {np.abs(pct_error).mean():.2f}%\")\n",
    "print(f\"Median Absolute Percentage Error: {np.abs(pct_error).median():.2f}%\")\n",
    "print(f\"RMSE (percentage): {np.sqrt((pct_error ** 2).mean()):.2f}%\")\n",
    "print(f\"\\nPercentage Error Distribution:\")\n",
    "print(pd.Series(pct_error).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Percentage Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of percentage errors\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(pct_error, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(pct_error.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {pct_error.mean():.2f}%')\n",
    "axes[0].axvline(pct_error.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {pct_error.median():.2f}%')\n",
    "axes[0].set_xlabel('Percentage Error (%)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Prediction Errors\\n(Predicted PE - Actual PE) / Actual PE', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(pct_error, vert=True)\n",
    "axes[1].set_ylabel('Percentage Error (%)', fontsize=12)\n",
    "axes[1].set_title('Box Plot of Prediction Errors', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print percentiles\n",
    "print(\"\\nPercentiles of Percentage Error:\")\n",
    "for p in [1, 5, 10, 25, 50, 75, 90, 95, 99]:\n",
    "    print(f\"{p:2d}th percentile: {np.percentile(pct_error, p):7.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(20), importance_df['importance'].head(20))\n",
    "plt.yticks(range(20), importance_df['feature'].head(20))\n",
    "plt.xlabel('Importance (Gain)', fontsize=12)\n",
    "plt.title('Top 20 Feature Importances - LightGBM Model', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Tree Structure\n",
    "\n",
    "We'll visualize the first three levels of two trees: Tree 0 (first tree) and Tree 50 (middle of training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Tree 0 (first tree)\n",
    "print(\"Plotting Tree 0 (first tree, first 3 levels)...\")\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "lgb.plot_tree(model, tree_index=0, figsize=(20, 10), show_info=['split_gain'], ax=ax)\n",
    "plt.title('Tree 0 - First Tree in Ensemble', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Tree 50 (middle tree)\n",
    "print(\"Plotting Tree 50 (middle tree, first 3 levels)...\")\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "lgb.plot_tree(model, tree_index=50, figsize=(20, 10), show_info=['split_gain'], ax=ax)\n",
    "plt.title('Tree 50 - Middle Tree in Ensemble', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance by Tree\n",
    "\n",
    "Compare feature importance between the two trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the booster object\n",
    "booster = model.booster_\n",
    "\n",
    "# Get importance for specific trees\n",
    "print(\"\\nFeature splits in Tree 0:\")\n",
    "tree_0_info = booster.trees_to_dataframe().query('tree_index == 0')\n",
    "if 'split_feature' in tree_0_info.columns:\n",
    "    tree_0_splits = tree_0_info['split_feature'].value_counts().head(10)\n",
    "    print(tree_0_splits)\n",
    "else:\n",
    "    print(\"No split information available\")\n",
    "\n",
    "print(\"\\nFeature splits in Tree 50:\")\n",
    "tree_50_info = booster.trees_to_dataframe().query('tree_index == 50')\n",
    "if 'split_feature' in tree_50_info.columns:\n",
    "    tree_50_splits = tree_50_info['split_feature'].value_counts().head(10)\n",
    "    print(tree_50_splits)\n",
    "else:\n",
    "    print(\"No split information available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual vs Predicted PE Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of actual vs predicted\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3, s=20)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual PE', fontsize=12)\n",
    "plt.ylabel('Predicted PE', fontsize=12)\n",
    "plt.title('Actual vs Predicted PE Ratios - November 2025', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nR-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'ticker': test_data['ticker'].values,\n",
    "    'actual_pe': y_test.values,\n",
    "    'predicted_pe': y_pred,\n",
    "    'pct_error': pct_error.values\n",
    "})\n",
    "\n",
    "print(\"\\nSample of predictions (sorted by absolute percentage error):\")\n",
    "results_df['abs_pct_error'] = np.abs(results_df['pct_error'])\n",
    "print(\"\\nBest predictions (lowest error):\")\n",
    "print(results_df.nsmallest(10, 'abs_pct_error')[['ticker', 'actual_pe', 'predicted_pe', 'pct_error']])\n",
    "\n",
    "print(\"\\nWorst predictions (highest error):\")\n",
    "print(results_df.nlargest(10, 'abs_pct_error')[['ticker', 'actual_pe', 'predicted_pe', 'pct_error']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
